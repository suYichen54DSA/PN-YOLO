# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""Loss functions."""

import torch
import torch.nn as nn

from utils.metrics import bbox_iou
from utils.torch_utils import de_parallel
import torch.nn.functional as F
import os
import piexif
# from datetime import datetime
import torch
import torch.nn.functional as F
import piexif
import datetime

def smooth_BCE(eps=0.1):
    """Returns label smoothing BCE targets for reducing overfitting; pos: `1.0 - 0.5*eps`, neg: `0.5*eps`. For details see https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441."""
    return 1.0 - 0.5 * eps, 0.5 * eps


class BCEBlurWithLogitsLoss(nn.Module):
    """Modified BCEWithLogitsLoss to reduce missing label effects in YOLOv5 training with optional alpha smoothing."""

    def __init__(self, alpha=0.05):
        """Initializes a modified BCEWithLogitsLoss with reduced missing label effects, taking optional alpha smoothing
        parameter.
        """
        super().__init__()
        self.loss_fcn = nn.BCEWithLogitsLoss(reduction="none")  # must be nn.BCEWithLogitsLoss()
        self.alpha = alpha

    def forward(self, pred, true):
        """Computes modified BCE loss for YOLOv5 with reduced missing label effects, taking pred and true tensors,
        returns mean loss.
        """
        loss = self.loss_fcn(pred, true)
        pred = torch.sigmoid(pred)  # prob from logits
        dx = pred - true  # reduce only missing label effects
        # dx = (pred - true).abs()  # reduce missing label and false label effects
        alpha_factor = 1 - torch.exp((dx - 1) / (self.alpha + 1e-4))
        loss *= alpha_factor
        return loss.mean()


class FocalLoss(nn.Module):
    """Applies focal loss to address class imbalance by modifying BCEWithLogitsLoss with gamma and alpha parameters."""

    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        """Initializes FocalLoss with specified loss function, gamma, and alpha values; modifies loss reduction to
        'none'.
        """
        super().__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = "none"  # required to apply FL to each element

    def forward(self, pred, true):
        """Calculates the focal loss between predicted and true labels using a modified BCEWithLogitsLoss."""
        loss = self.loss_fcn(pred, true)
        # p_t = torch.exp(-loss)
        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability

        # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py
        pred_prob = torch.sigmoid(pred)  # prob from logits
        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = (1.0 - p_t) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == "mean":
            return loss.mean()
        elif self.reduction == "sum":
            return loss.sum()
        else:  # 'none'
            return loss


class QFocalLoss(nn.Module):
    """Implements Quality Focal Loss to address class imbalance by modulating loss based on prediction confidence."""

    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        """Initializes Quality Focal Loss with given loss function, gamma, alpha; modifies reduction to 'none'."""
        super().__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = "none"  # required to apply FL to each element

    def forward(self, pred, true):
        """Computes the focal loss between `pred` and `true` using BCEWithLogitsLoss, adjusting for imbalance with
        `gamma` and `alpha`.
        """
        loss = self.loss_fcn(pred, true)

        pred_prob = torch.sigmoid(pred)  # prob from logits
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = torch.abs(true - pred_prob) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == "mean":
            return loss.mean()
        elif self.reduction == "sum":
            return loss.sum()
        else:  # 'none'
            return loss




class ComputeLoss:
    def __init__(self, model, paths=None, autobalance=False, margin=0.3, alpha=0.1,
                 proto_weight=0.4, contrast_weight=0.6, time_factor=0.01, momentum=0.9):
        self.device = next(model.parameters()).device
        self.margin = margin
        self.alpha = alpha
        self.proto_weight = proto_weight
        self.contrast_weight = contrast_weight
        self.time_factor = time_factor
        self.momentum = momentum

    def extract_date_from_exif(self, image_path):
        """æå–å›¾åƒ EXIF æ—¥æœŸä¿¡æ¯ä¸º 'YYYY-MM-DD'"""
        exif_dict = piexif.load(image_path)
        time_str = exif_dict['Exif'].get(piexif.ExifIFD.DateTimeOriginal, None)
        if time_str is None:
            raise ValueError(f"å›¾åƒ {image_path} ç¼ºå°‘ DateTimeOriginal EXIF ä¿¡æ¯")
        if isinstance(time_str, bytes):
            time_str = time_str.decode("utf-8")
        date_part = time_str.split(" ")[0].replace(":", "-")
        return date_part

    def date_diff_in_days(self, date1_str, date2_str):
        """è¿”å›ä¸¤ä¸ªæ—¥æœŸå­—ç¬¦ä¸²ä¹‹é—´çš„å¤©æ•°å·®"""
        date_format = "%Y-%m-%d"
        d1 = datetime.datetime.strptime(date1_str, date_format)
        d2 = datetime.datetime.strptime(date2_str, date_format)
        return abs((d1 - d2).days)

    def compute_prototypes(self, p_list, paths):
        """æŒ‰å›¾åƒæ—¥æœŸè®¡ç®—æ¯å±‚çš„ç±»åˆ«åŸå‹"""
        date_tags = [self.extract_date_from_exif(path) for path in paths]
        proto_dicts = [{} for _ in range(len(p_list))]
        count_dicts = [{} for _ in range(len(p_list))]

        for i, p in enumerate(p_list):
            p_flat = p.view(p.size(0), -1)
            for j in range(p.size(0)):
                category = date_tags[j]
                if category not in proto_dicts[i]:
                    proto_dicts[i][category] = torch.zeros_like(p_flat[j]).to(self.device)
                    count_dicts[i][category] = 0
                proto_dicts[i][category] += p_flat[j]
                count_dicts[i][category] += 1

        for i in range(len(proto_dicts)):
            for key in proto_dicts[i]:
                proto_dicts[i][key] /= count_dicts[i][key]

        return proto_dicts

    def triplet_loss(self, p_list, paths, proto_dicts):
        """æŒ‰å›¾åƒæ—¥æœŸè®¡ç®— Triplet Lossï¼ˆæ”¯æŒæ—¶é—´å·®åŠ¨æ€ marginï¼‰"""
        date_tags = [self.extract_date_from_exif(path) for path in paths]
        total_triplet_loss = 0

        for i, p in enumerate(p_list):
            p_flat = p.view(p.size(0), -1)
            triplet_losses = []
            for j in range(p.size(0)):
                anchor = p_flat[j]
                category = date_tags[j]
                pos_proto = proto_dicts[i].get(category, None)
                neg_proto = None
                neg_category = None
                for key in proto_dicts[i]:
                    if key != category:
                        neg_proto = proto_dicts[i][key]
                        neg_category = key
                        break

                if pos_proto is not None and neg_proto is not None:
                    d_pos = F.pairwise_distance(anchor.unsqueeze(0), pos_proto.unsqueeze(0))
                    d_neg = F.pairwise_distance(anchor.unsqueeze(0), neg_proto.unsqueeze(0))
                    time_diff = self.date_diff_in_days(category, neg_category)
                    time_margin = self.time_factor * time_diff
                    margin = self.alpha * torch.mean(d_pos).detach() + time_margin
                    triplet_loss_sample = F.relu(d_pos - d_neg + margin)
                    triplet_losses.append(triplet_loss_sample)

            if triplet_losses:
                total_triplet_loss += torch.mean(torch.stack(triplet_losses))
        return total_triplet_loss

    def contrastive_loss(self, p_list, paths):
        """æŒ‰å›¾åƒæ—¥æœŸè®¡ç®— InfoNCE å¯¹æ¯”æŸå¤±"""
        date_tags = [self.extract_date_from_exif(path) for path in paths]
        total_contrast_loss = 0
        for i, p in enumerate(p_list):
            p_flat = p.view(p.size(0), -1)
            losses = []
            for j in range(p.size(0)):
                for k in range(j + 1, p.size(0)):
                    cosine_sim = F.cosine_similarity(p_flat[j].unsqueeze(0), p_flat[k].unsqueeze(0), dim=-1)
                    date1 = date_tags[j]
                    date2 = date_tags[k]
                    time_diff = self.date_diff_in_days(date1, date2)
                    time_weight = 1 + self.time_factor * time_diff
                    if date1 == date2:
                        loss_val = F.relu((1 - cosine_sim) / time_weight)
                    else:
                        loss_val = F.relu(cosine_sim * time_weight)
                    losses.append(loss_val)
            if losses:
                total_contrast_loss += torch.mean(torch.stack(losses))
        return total_contrast_loss

    def __call__(self, p_list, paths):
        """èåˆ Triplet ä¸ Contrastive å¤šå±‚æŸå¤±"""
        proto_dicts = self.compute_prototypes(p_list, paths)
        t_loss = self.triplet_loss(p_list, paths, proto_dicts)
        c_loss = self.contrastive_loss(p_list, paths)
        total_loss = self.proto_weight * t_loss + self.contrast_weight * c_loss
        return total_loss




# class ComputeLoss:
#     def __init__(self, model, paths=None, autobalance=False, margin=0.3, alpha=0.1,
#                  proto_weight=0.4, contrast_weight=0.6, time_factor=0.01, momentum=0.9):
#         """
#         time_factor: ç”¨äºè°ƒèŠ‚æ—¶é—´å·®å¯¹æŸå¤±çš„å½±å“ï¼Œå€¼è¶Šå¤§æ—¶é—´å·®çš„å½±å“è¶Šæ˜æ˜¾ã€‚
#         """
#         self.device = next(model.parameters()).device  
#         self.margin = margin  
#         self.alpha = alpha  
#         self.proto_weight = proto_weight  
#         self.contrast_weight = contrast_weight
#         self.time_factor = time_factor
#         self.momentum = momentum

#         # # æ³¨å†Œæ¯ä¸€å±‚çš„åŸå‹å­—å…¸ä½œä¸º buffer
#         # self.num_layers = len(model.backbone)  # å‡è®¾è¿™æ˜¯ä½ çš„ backbone å±‚æ•°
#         # for i in range(3):
#         #     # æ³¨å†ŒåŸå‹å­—å…¸
#         #     self.register_buffer(f'proto_dict_layer{i}', {})

#     def compute_prototypes(self, p_list, paths):
#         """
#         å¯¹ p_list ä¸­æ¯ä¸€å±‚ï¼ŒæŒ‰ç…§å›¾ç‰‡çš„çˆ¶ç›®å½•ï¼ˆå‡è®¾ä¸ºæ—¥æœŸå­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "2024-09-09"ï¼‰è®¡ç®—ç±»åˆ«åŸå‹ã€‚
#         è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸€é¡¹ä¸ºå¯¹åº”å±‚çš„ç±»åˆ«åŸå‹å­—å…¸ã€‚
#         """
#         parent_dirs = [os.path.basename(os.path.dirname(path)) for path in paths]
#         proto_dicts = [{} for _ in range(len(p_list))]
#         count_dicts = [{} for _ in range(len(p_list))]

#         for i, p in enumerate(p_list):
#             # å°†æ¯ä¸ªç‰¹å¾å±•å¹³ä¸º (batch_size, feature_dim)
#             p_flat = p.view(p.size(0), -1)
#             for j in range(p.size(0)):
#                 category = parent_dirs[j]
#                 if category not in proto_dicts[i]:
#                     proto_dicts[i][category] = torch.zeros_like(p_flat[j]).to(self.device)
#                     count_dicts[i][category] = 0
#                 proto_dicts[i][category] += p_flat[j]
#                 count_dicts[i][category] += 1

#         for i in range(len(proto_dicts)):
#             for key in proto_dicts[i]:
#                 proto_dicts[i][key] /= count_dicts[i][key]

#         return proto_dicts

#     def triplet_loss(self, p_list, paths, proto_dicts):
#         """
#         å¯¹æ¯ä¸€å±‚è®¡ç®— Triplet Lossï¼š  
#           - ä½¿ç”¨çˆ¶ç›®å½•ï¼ˆæ—¥æœŸå­—ç¬¦ä¸²ï¼‰ä½œä¸ºç±»åˆ«æ ‡ç­¾ã€‚  
#           - åœ¨è´Ÿæ ·æœ¬é€‰æ‹©æ—¶ï¼Œè®¡ç®—å½“å‰æ ·æœ¬ï¼ˆanchorï¼‰çš„æ—¥æœŸä¸è´Ÿç±»åˆ«æ—¥æœŸä¹‹é—´çš„æ—¶é—´å·®ï¼Œ  
#             å¹¶ä¹˜ä»¥ time_factor ååŠ å…¥åˆ° margin ä¸­ã€‚
#         """
#         parent_dirs = [os.path.basename(os.path.dirname(path)) for path in paths]
#         total_triplet_loss = 0

#         for i, p in enumerate(p_list):
#             p_flat = p.view(p.size(0), -1)
#             triplet_losses = []
#             for j in range(p.size(0)):
#                 anchor = p_flat[j]
#                 category = parent_dirs[j]
#                 pos_proto = proto_dicts[i].get(category, None)
#                 neg_proto = None
#                 neg_category = None
#                 # é€‰æ‹©ä¸€ä¸ªè´Ÿç±»åˆ«åŸå‹ï¼ˆè¿™é‡Œç®€å•é€‰æ‹©ç¬¬ä¸€ä¸ªä¸åŒç±»åˆ«çš„åŸå‹ï¼‰
#                 for key in proto_dicts[i]:
#                     if key != category:
#                         neg_proto = proto_dicts[i][key]
#                         neg_category = key
#                         break

#                 if pos_proto is not None and neg_proto is not None:
#                     d_pos = F.pairwise_distance(anchor.unsqueeze(0), pos_proto.unsqueeze(0))
#                     d_neg = F.pairwise_distance(anchor.unsqueeze(0), neg_proto.unsqueeze(0))
#                     # æ ¹æ® anchor ä¸è´Ÿæ ·æœ¬å¯¹åº”çš„æ—¥æœŸè®¡ç®—æ—¶é—´å·®ï¼ˆå•ä½ï¼šå¤©ï¼‰
#                     time_diff = date_diff_in_days(category, neg_category)
#                     time_margin = self.time_factor * time_diff  # æ—¶é—´å·®å¸¦æ¥çš„é¢å¤– margin
#                     # åŠ¨æ€ marginï¼šåŸºç¡€ margin æ ¹æ® d_pos çš„å‡å€¼è®¡ç®—ï¼Œå†åŠ ä¸Šæ—¶é—´ä¿¡æ¯
#                     margin = self.alpha * torch.mean(d_pos).detach() + time_margin
#                     triplet_loss_sample = F.relu(d_pos - d_neg + margin)
#                     triplet_losses.append(triplet_loss_sample)

#             if triplet_losses:
#                 total_triplet_loss += torch.mean(torch.stack(triplet_losses))
#         return total_triplet_loss

#     def contrastive_loss(self, p_list, paths):
#         """
#         å¯¹æ¯ä¸€å±‚è®¡ç®— InfoNCE å¯¹æ¯”æŸå¤±ï¼š  
#           - å¯¹äºæ¯ä¸€å¯¹æ ·æœ¬ï¼Œè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ã€‚  
#           - æ ¹æ®å¯¹åº”çš„æ—¥æœŸè®¡ç®—æ—¶é—´å·®ï¼Œè¿›è€Œè®¾è®¡ä¸€ä¸ªæƒé‡ time_weightï¼Œ  
#             å½“æ—¶é—´å·®è¶Šå¤§æ—¶ï¼Œç›¸ä¼¼åº¦çº¦æŸè¶Šå¼ºæˆ–æƒ©ç½šè¶Šå¤§ã€‚
#         """
#         parent_dirs = [os.path.basename(os.path.dirname(path)) for path in paths]
#         total_contrast_loss = 0
#         for i, p in enumerate(p_list):
#             p_flat = p.view(p.size(0), -1)
#             losses = []
#             for j in range(p.size(0)):
#                 for k in range(j + 1, p.size(0)):
#                     cosine_sim = F.cosine_similarity(p_flat[j].unsqueeze(0), p_flat[k].unsqueeze(0), dim=-1)
#                     date1 = parent_dirs[j]
#                     date2 = parent_dirs[k]
#                     time_diff = date_diff_in_days(date1, date2)
#                     # å½“æ—¶é—´å·®è¶Šå¤§æ—¶ï¼Œæƒé‡è¶Šå¤§ï¼ˆè¿™é‡Œç®€å•è®¾è®¡ä¸º 1 + time_factor * time_diffï¼‰
#                     time_weight = 1 + self.time_factor * time_diff
#                     if date1 == date2:
#                         # åŒä¸€æ—¥æœŸï¼šæœŸæœ›ç‰¹å¾æ›´ç›¸ä¼¼ï¼Œå› æ­¤ç›®æ ‡æ˜¯ (1 - cosine_sim)
#                         loss_val = F.relu((1 - cosine_sim) / time_weight)
#                     else:
#                         # ä¸åŒæ—¥æœŸï¼šæœŸæœ›ç‰¹å¾æ›´ä¸ç›¸ä¼¼ï¼Œå› æ­¤ç›®æ ‡æ˜¯å¢å¤§ cosine_sim
#                         loss_val = F.relu(cosine_sim * time_weight)
#                     losses.append(loss_val)
#             if losses:
#                 total_contrast_loss += torch.mean(torch.stack(losses))
#         return total_contrast_loss

#     def __call__(self, p_list, paths):
#         """
#         è®¡ç®—æœ€ç»ˆæŸå¤±ï¼šèåˆäº† Triplet Loss å’Œ Contrastive Lossï¼Œ  
#         å¹¶åˆ†åˆ«å¯¹å„å±‚è®¡ç®—åæ±‚å’Œã€‚
#         """
#         proto_dicts = self.compute_prototypes(p_list, paths)
#         t_loss = self.triplet_loss(p_list, paths, proto_dicts)
#         c_loss = self.contrastive_loss(p_list, paths)
#         total_loss = self.proto_weight * t_loss + self.contrast_weight * c_loss
#         return total_loss
